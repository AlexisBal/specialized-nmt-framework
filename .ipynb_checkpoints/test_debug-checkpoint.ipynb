{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f58be6-ecec-4f97-8efc-74b064b5b86e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Erreur calcul similarité: name 'uroman_result' is not defined\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Remplacez par vos vraies fonctions\\nfrom utils.pinyin_functions import get_pinyin, calculate_name_similarity\\n\\ntry:\\n    real_pinyin = get_pinyin(chinese_word, None)  # Votre pinyin_dictionary\\n    real_similarity = calculate_name_similarity(uroman_result, real_pinyin)\\n\\n    print(f\"\\n4. Test avec vraies fonctions:\")\\n    print(f\"   Vrai pinyin: {real_pinyin}\")\\n    print(f\"   Vraie similarité: {real_similarity:.3f}\")\\n\\n    real_final = real_similarity + (0.2 if 2 <= len(chinese_word) <= 4 else 0)\\n    print(f\"   Score final réel: {real_final:.3f}\")\\n    print(f\"   Passe le seuil: {\\'✅ OUI\\' if real_final >= 0.56 else \\'❌ NON\\'}\")\\n\\nexcept Exception as e:\\n    print(f\"❌ Erreur fonctions réelles: {e}\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Jupyter pour vérifier la translittération uroman et la similarité\n",
    "# Cas : מהללאל → 瑪勒列\n",
    "\n",
    "# 1. Test uroman\n",
    "try:\n",
    "    import uroman as ur\n",
    "    uroman_instance = ur.Uroman()\n",
    "    hebrew_word = \"מהללאל\"\n",
    "    uroman_result = uroman_instance.romanize_string(hebrew_word)\n",
    "    print(f\"1. Translittération uroman:\")\n",
    "    print(f\"   Hébreu: {hebrew_word}\")\n",
    "    print(f\"   Uroman: {uroman_result}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur uroman: {e}\")\n",
    "\n",
    "# 2. Test pinyin (simulé - remplacez par votre vraie fonction)\n",
    "def get_pinyin_mock(chinese_word, pinyin_dict=None):\n",
    "    \"\"\"Mock de get_pinyin - remplacez par votre vraie fonction\"\"\"\n",
    "    pinyin_map = {\n",
    "        \"瑪勒列\": \"Ma3 Le4 Lie4\",\n",
    "        # Ajoutez d'autres si nécessaire\n",
    "    }\n",
    "    return pinyin_map.get(chinese_word, chinese_word)\n",
    "\n",
    "chinese_word = \"瑪勒列\"\n",
    "pinyin_result = get_pinyin_mock(chinese_word)\n",
    "print(f\"\\n2. Pinyin chinois:\")\n",
    "print(f\"   Chinois: {chinese_word}\")\n",
    "print(f\"   Pinyin: {pinyin_result}\")\n",
    "\n",
    "# 3. Test similarité (simulé - remplacez par votre vraie fonction)\n",
    "def calculate_name_similarity(english_name, pinyin):\n",
    "    \"\"\"\n",
    "    Calcule la similarité phonétique pour noms propres anglais-chinois\n",
    "    \"\"\"\n",
    "    \n",
    "    # Nettoyer le pinyin (enlever les tons et espaces)\n",
    "    clean_pinyin = re.sub(r'[0-9]', '', pinyin.lower()).replace(' ', '')\n",
    "    english_clean = english_name.lower()\n",
    "    \n",
    "    # Longueur minimale de correspondance\n",
    "    # Rejeter si les noms sont trop courts pour être fiables\n",
    "    if len(english_clean) < 3 or len(clean_pinyin) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    # 1. CORRESPONDANCES PHONÉTIQUES\n",
    "    phonetic_map = {\n",
    "        \n",
    "        # Consonnes de base\n",
    "        'br': 'bo',\n",
    "        'ham': 'han',\n",
    "        'a': 'ya',\n",
    "        'e': 'yi',\n",
    "        \n",
    "        # Phonétique générale\n",
    "        'j': 'y',           # Jacob → Ya\n",
    "        'c': 'k',           # Isaac → Yi-sak (mais 'k' souvent omis)\n",
    "        'ch': 'ke',         # Michael → Mi-ke\n",
    "        'ck': 'ke',         # Jack → Ya-ke\n",
    "        'x': 'kesi',        # Alexander → A-li-shan-de\n",
    "        'th': 't',          # Matthew → Ma-tai\n",
    "        'ph': 'f',          # Philip → Fei-li\n",
    "        \n",
    "        # Groupes consonantiques simplifiés\n",
    "        'br': 'bo',         # Abraham → A-bo-la-han\n",
    "        'gr': 'ge',         # Grace → Ge-rui-si\n",
    "        'pr': 'pu',         # Peter → Pu-de\n",
    "        'tr': 'te',         # Patrick → Pa-te-li\n",
    "        'dr': 'de',         # Andrew → An-de-lu\n",
    "        'fr': 'fu',         # Francis → Fu-lan-xi\n",
    "        'cr': 'ke',         # Chris → Ke-li-si\n",
    "        \n",
    "        # Voyelles adaptées\n",
    "        'aa': 'a',          # Isaac → Yi-sa\n",
    "        'ee': 'i',          # Lee → Li\n",
    "        'oo': 'u',          # Book → Bu-ke\n",
    "        'ou': 'ao',         # House → Hao-si\n",
    "        'ow': 'ao',         # Brown → Bu-lao-en\n",
    "        'ey': 'ei',         # Grey → Ge-lei\n",
    "        'ay': 'ai',         # David → Da-wei (approximatif)\n",
    "        'oy': 'ao',         # Troy → Te-lao-yi\n",
    "        \n",
    "        # Sons difficiles\n",
    "        'v': 'w',         # David → Da-wei (v → w → wei)\n",
    "        \n",
    "        # Simplifications\n",
    "        'bb': 'b', 'cc': 'k', 'dd': 'd', 'ff': 'f', 'gg': 'g',\n",
    "        'll': 'l', 'mm': 'm', 'nn': 'n', 'pp': 'p', 'rr': 'r',\n",
    "        'ss': 's', 'tt': 't'\n",
    "    }\n",
    "    \n",
    "    # 2. RÈGLES POSITIONNELLES\n",
    "    def apply_smart_mapping(text):\n",
    "        \"\"\"Applique des règles intelligentes selon la position\"\"\"\n",
    "        result = text\n",
    "        \n",
    "        # Préfixes silencieux\n",
    "        if result.startswith('kn'):    result = result[2:]      # Knight → ight\n",
    "        if result.startswith('ps'):    result = result[1:]      # Psalm → salm\n",
    "        if result.startswith('wr'):    result = result[1:]      # Wright → right\n",
    "        \n",
    "        # Suffixes simplifiés\n",
    "        if result.endswith('mb'):      result = result[:-1]     # Lamb → Lam\n",
    "        if result.endswith('gn'):      result = result[:-2] + 'n'  # Sign → Sin\n",
    "        if result.endswith('bt'):      result = result[:-2] + 't'  # Debt → Det\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # 3. GÉNÉRER DES VARIANTES DE TRANSCRIPTION POSSIBLES\n",
    "    mapped_english = apply_smart_mapping(english_clean)\n",
    "    \n",
    "    # Générer plusieurs variantes possibles\n",
    "    def generate_transcription_variants(text, phonetic_map, max_variants=5):\n",
    "        \"\"\"Génère plusieurs variantes de transcription possibles\"\"\"\n",
    "        variants = [text]  # Commencer avec le texte original\n",
    "        \n",
    "        # Pour chaque règle phonétique, créer des variantes\n",
    "        for eng_sound, chi_sound in sorted(phonetic_map.items(), key=len, reverse=True):\n",
    "            if eng_sound in text:\n",
    "                new_variants = []\n",
    "                for variant in variants[:max_variants]:  # Limiter pour éviter explosion combinatoire\n",
    "                    # Garder la variante originale\n",
    "                    new_variants.append(variant)\n",
    "                    # Ajouter la variante avec remplacement\n",
    "                    new_variant = variant.replace(eng_sound, chi_sound)\n",
    "                    if new_variant != variant:  # Éviter les doublons\n",
    "                        new_variants.append(new_variant)\n",
    "                variants = new_variants[:max_variants]  # Garder les N meilleures\n",
    "        \n",
    "        return variants\n",
    "    \n",
    "    english_variants = generate_transcription_variants(mapped_english, phonetic_map)\n",
    "    \n",
    "    # 4. CALCUL DE SIMILARITÉ MULTI-VARIANTES\n",
    "    \n",
    "    # Fonction utilitaire pour les syllabes\n",
    "    def get_syllables(text, min_len=2):\n",
    "        \"\"\"Extraire des syllabes approximatives\"\"\"\n",
    "        syllables = []\n",
    "        for i in range(len(text) - min_len + 1):\n",
    "            for length in [3, 2]:  # Priorité aux syllabes de 3 puis 2 caractères\n",
    "                if i + length <= len(text):\n",
    "                    syl = text[i:i+length]\n",
    "                    syllables.append(syl)\n",
    "        return set(syllables)\n",
    "    \n",
    "    # Tester chaque variante anglaise contre le pinyin chinois\n",
    "    best_scores = {\n",
    "        'direct': 0.0,\n",
    "        'syllable': 0.0,\n",
    "        'length_ratio': 0.0\n",
    "    }\n",
    "    \n",
    "    for variant in english_variants:\n",
    "        # A. Similarité directe après mapping\n",
    "        direct_sim = difflib.SequenceMatcher(None, variant, clean_pinyin).ratio()\n",
    "        \n",
    "        # B. Correspondances syllabiques\n",
    "        variant_syllables = get_syllables(variant)\n",
    "        pinyin_syllables = get_syllables(clean_pinyin)\n",
    "        \n",
    "        syllable_intersection = len(variant_syllables & pinyin_syllables)\n",
    "        syllable_union = len(variant_syllables | pinyin_syllables)\n",
    "        syllable_sim = syllable_intersection / syllable_union if syllable_union > 0 else 0\n",
    "        \n",
    "        # C. Ratio de longueur pour cette variante\n",
    "        length_ratio = min(len(variant), len(clean_pinyin)) / max(len(variant), len(clean_pinyin))\n",
    "        \n",
    "        # Garder les meilleurs scores\n",
    "        best_scores['direct'] = max(best_scores['direct'], direct_sim)\n",
    "        best_scores['syllable'] = max(best_scores['syllable'], syllable_sim)\n",
    "        best_scores['length_ratio'] = max(best_scores['length_ratio'], length_ratio)\n",
    "    \n",
    "    # Utiliser les meilleurs scores obtenus\n",
    "    direct_similarity = best_scores['direct']\n",
    "    syllable_similarity = best_scores['syllable']\n",
    "    length_ratio = best_scores['length_ratio']\n",
    "    \n",
    "    # NOUVEAU : Pénalité forte si différence de longueur trop importante\n",
    "    length_penalty = 1.0\n",
    "    # Calculer sur la base de la meilleure variante (plus court chemin)\n",
    "    min_length_diff = min(abs(len(variant) - len(clean_pinyin)) for variant in english_variants)\n",
    "    \n",
    "    if min_length_diff > 3:  # Plus de 3 caractères de différence\n",
    "        length_penalty = 0.5\n",
    "    elif min_length_diff > 5:  # Plus de 5 caractères\n",
    "        length_penalty = 0.2\n",
    "    \n",
    "    # D. NOUVEAU : Vérification de cohérence phonétique minimale\n",
    "    # Au moins 30% de correspondance directe OU 40% syllabique requis\n",
    "    min_phonetic_threshold = max(direct_similarity, syllable_similarity * 1.2)\n",
    "    if min_phonetic_threshold < 0.25:\n",
    "        return 0.0  # Rejet immédiat\n",
    "    \n",
    "    # 5. SCORE FINAL AVEC PONDÉRATION AJUSTÉE\n",
    "    final_score = (\n",
    "        direct_similarity * 0.5 +           # Correspondance directe (50%)\n",
    "        syllable_similarity * 0.3 +         # Correspondance syllabique (30%)\n",
    "        length_ratio * 0.1 +                # Ratio de longueur (10%)\n",
    "        min_phonetic_threshold * 0.1        # Bonus cohérence (10%)\n",
    "    ) * length_penalty  # Appliquer la pénalité\n",
    "    \n",
    "    return min(1.0, final_score)  # Cap à 1.0\n",
    "\n",
    "try:\n",
    "    similarity = calculate_name_similarity(uroman_result, pinyin_result)\n",
    "    print(f\"\\n3. Calcul de similarité:\")\n",
    "    print(f\"   Uroman: '{uroman_result}'\")\n",
    "    print(f\"   Pinyin: '{pinyin_result}'\")\n",
    "    print(f\"   Similarité: {similarity:.3f}\")\n",
    "    \n",
    "    # Bonus longueur chinoise (2-4 caractères)\n",
    "    chinese_length = len(chinese_word)\n",
    "    bonus = 0.2 if 2 <= chinese_length <= 4 else 0\n",
    "    final_score = similarity + bonus\n",
    "    \n",
    "    print(f\"   Bonus longueur (+0.2): {bonus}\")\n",
    "    print(f\"   Score final: {final_score:.3f}\")\n",
    "    \n",
    "    # Test seuil\n",
    "    threshold = 0.56\n",
    "    passes_threshold = final_score >= threshold\n",
    "    print(f\"   Seuil: {threshold}\")\n",
    "    print(f\"   Passe le seuil: {'✅ OUI' if passes_threshold else '❌ NON'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur calcul similarité: {e}\")\n",
    "\n",
    "# 4. Test avec vos vraies fonctions (décommentez si disponibles)\n",
    "\"\"\"\n",
    "# Remplacez par vos vraies fonctions\n",
    "from utils.pinyin_functions import get_pinyin, calculate_name_similarity\n",
    "\n",
    "try:\n",
    "    real_pinyin = get_pinyin(chinese_word, None)  # Votre pinyin_dictionary\n",
    "    real_similarity = calculate_name_similarity(uroman_result, real_pinyin)\n",
    "    \n",
    "    print(f\"\\n4. Test avec vraies fonctions:\")\n",
    "    print(f\"   Vrai pinyin: {real_pinyin}\")\n",
    "    print(f\"   Vraie similarité: {real_similarity:.3f}\")\n",
    "    \n",
    "    real_final = real_similarity + (0.2 if 2 <= len(chinese_word) <= 4 else 0)\n",
    "    print(f\"   Score final réel: {real_final:.3f}\")\n",
    "    print(f\"   Passe le seuil: {'✅ OUI' if real_final >= 0.56 else '❌ NON'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur fonctions réelles: {e}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840c0f6-4716-4f6b-a642-70457a84aaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d98351-017e-40ec-840d-e37f98384e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2fb53-4324-4fc9-87f1-1b0cb773c23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb97e2-0ab6-4ac2-a0dc-5d4bd32d53ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4eb2a4-267e-4d94-8298-f06d92c676c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff775ba-6611-4f06-b8db-1eb297fe4733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa19abb-d9a3-4252-8077-1c3932c4e060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f1950-abcf-4240-91c0-713ed4724a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810cdbf-7e69-4d74-8126-d45cd31e828d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
